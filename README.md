# cifar100_CNN

This project aims to achieve as accurate as possible when recognizing images in the cifar-100 dataset. Algorithms used were SVM, KNN and CNN. The highest accuracy observed was 60% when using CNN. 

In the state of pre-processing the data, 80% of variance / 25 features were kept in order to decrease computing complexity.

    CNN is a neural network that specialize in image recognition, CNN usually takes 3 channels (RGB) image or 1 channel (black and white) image as input. By applying filter which usually is a matrix on the image to producing feature maps. Where the size of feature maps depend on the size of the filters. The values in filter matrix was usually unknown, every time a train data pass through, the values in filter matrix would be updated by back-propagation procedure. To prevent the model from being linear, a non-linear activation function was usually applied on the feature maps. Then by pooling and flattening the feature map, a 1 x (width x height x channel) matrix would be formed to pass into the fully connected network.
    In this project, a CNN was trained and used to make prediction. GPU was used in order to train the model. Due to the lack of GPU resource on local machine the model was trained on Kaggle kernel. For which provided a free-to-use GPU resource that could significantly shorten the computation time.
    Unlike the other two algorithm implemented, the cifar100 data set was imported using keras.datasets package. Cifar100 data set consisted 50000 training data and 10000 test data. Each samples in cifar100 data set consisted a RGB image, 32 in height and 32 in width, leading each of the image to be a 32x32x3 tensor. For pre-processing, the 32x32x3 tensor in both train and test set were first converted to 32 bits floating point number, then each value in the tensor was normalized by dividing the value by its standard deviation of the tensor, such that the every floating point number was restrained to be within 0 and 1. The label data were also converted into 32 bits integer which could be potentially easier to manipulate.
    Afterward, in order to increase the prediction accuracy, image pre-processing technique was
implemented. Image data generator package from keras was imported to implement image aug- mentation. The rotation range was set to be 20 degree, meaning that the generated image might have a rotation as much as 20 degree; the horizontal flip argument was set to be true, allowing to generate horizontal-flip images of the original images; the width and height shift range were both set to be 0.1, allowing the new generated image to move horizontally or vertically. After applying the image data generator, a new set of training data containing the original data and their transformations were used to train the data. Due to the increase in size, it might consume more computing power and computation time to train the model, yet this data augmentation technique could potentially increase the prediction accuracy.
    As shown in following figure, when constructing the convolutional layers, three 2-dimensional con- volutional layers were constructed. The first 2-dimensional convolutional layer accepted the (32, 32, 3) training data, applying 128 filters on it, with 3x3 convolution window. Padding was added evenly around each images. The activation function was set to Rectified Linear Unit (relu), which covnert all negative input into 0. Between the first 2-dimensional convolutional layer and second 2-dimensional convolutional layer, a normalization layer was added to keep the data normalized.
    The second and the third 2-dimensional convolutional layer both had 64 filters and had 3x3convolution window, the padding was set to be same and the activation function used was relu. Normalization layers were added after each convolutional layer to normalize the data. After the normalization layer, two max pooling layers were added with kernel size of 3x3. Meaning that the 3x3 matrix would be condense into a single value which would be the largest value in the matrix. Padding for both pooling layers were set to be same.
    After flattening the matrix, the train data were passed to three dense layers. The first layer was consisted of 512 units, using relu as activation function. After the first dense layer, a nor- malization and dropout layer was added, in order to normalized the training data. The dropout was set to be 0.5, meaning that for each training, 50% of the units would be in-activated, which could theoretically improve the performance of the model (Srivastava, et al., 2014). The second dense layer was consisted of 256 units, using relu as activation function, a 50% dropout layer and a normalization layer were also added after this dense layer. For the last fully connected layer, number of units were set to be 100, where each of the units represent one label, soft max was used as activation function, which could convert vectors of number into probability of labels.
    When training the model, rather than having the optimizes using Stochastic gradient descent, Adam was adopted, which could theoretically accelerate computation time and lower memory usage (Kingma & Ba, 2015).
    When training the model, epochs was set to be 500 and batch size was set to be 256. When training the mdoel, the validation set used was the test data from cifar100, therefore, the val- idation accuracy would simply be the prediction accuracy of the CNN model. After training, weights for each of the parameters were saved in a .h5 file for future usage.
    After training the CNN models, in order to distinguish the impact of learning rate and image augmentation technique, the code was executed twice more with 50 epochs each, and with different parameters. Model obtained from run 1 was considered as the primary model, with learning rate set to 5e-3 and image generator enabled; run 2 was the execution that with learning rate 1e-3 and image generator enabled; run 3 was the execution that with learning rate 5e-3 and image generator disabled. The run time, test and validation accuracy were then used to identify the impact of different parameters. A separate execution was done without GPU at the end, in order to identify if the usage of GPU would increase the performance and decrease the model training time.

<img width="528" alt="model_summary_figure" src="https://user-images.githubusercontent.com/100908727/161408997-6506316b-a873-48f0-94ca-b6384d03d9a6.png">
