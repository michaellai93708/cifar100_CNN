{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "group84_other_algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BM66LpEPbK-D"
      },
      "source": [
        "Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smN5zaaaar-N",
        "execution": {
          "iopub.status.busy": "2021-11-06T10:45:05.62546Z",
          "iopub.execute_input": "2021-11-06T10:45:05.625795Z",
          "iopub.status.idle": "2021-11-06T10:45:09.140209Z",
          "shell.execute_reply.started": "2021-11-06T10:45:05.625712Z",
          "shell.execute_reply": "2021-11-06T10:45:09.139307Z"
        },
        "trusted": true
      },
      "source": [
        "#block 1: Download cifar-100 data installation package from website\n",
        "!wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wuVlXYOa-lQ",
        "execution": {
          "iopub.status.busy": "2021-10-26T07:02:41.02436Z",
          "iopub.execute_input": "2021-10-26T07:02:41.024655Z",
          "iopub.status.idle": "2021-10-26T07:02:44.1054Z",
          "shell.execute_reply.started": "2021-10-26T07:02:41.024622Z",
          "shell.execute_reply": "2021-10-26T07:02:44.104014Z"
        },
        "trusted": true
      },
      "source": [
        " #block 2: Unzip the data package\n",
        " !tar -xf cifar-100-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7GNrvEmbFMl",
        "execution": {
          "iopub.status.busy": "2021-10-26T07:02:44.107132Z",
          "iopub.execute_input": "2021-10-26T07:02:44.107441Z",
          "iopub.status.idle": "2021-10-26T07:02:44.876846Z",
          "shell.execute_reply.started": "2021-10-26T07:02:44.107396Z",
          "shell.execute_reply": "2021-10-26T07:02:44.875631Z"
        },
        "trusted": true
      },
      "source": [
        " #block 3: named\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "      dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "train_data = np.array(unpickle(\"cifar-100-python/train\")[b'data'])\n",
        "test_data = np.array(unpickle(\"cifar-100-python/test\")[b'data'])\n",
        "\n",
        "train_label = np.array(unpickle(\"cifar-100-python/train\")[b'fine_labels'])\n",
        "test_label = np.array(unpickle(\"cifar-100-python/test\")[b'fine_labels'])\n",
        "\n",
        "labels_names = unpickle(\"cifar-100-python/meta\")[b'fine_label_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hypKxs9ObO6h"
      },
      "source": [
        "pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NudfvYpubRf-",
        "execution": {
          "iopub.status.busy": "2021-10-26T07:02:44.878711Z",
          "iopub.execute_input": "2021-10-26T07:02:44.878944Z",
          "iopub.status.idle": "2021-10-26T07:02:46.165418Z",
          "shell.execute_reply.started": "2021-10-26T07:02:44.878916Z",
          "shell.execute_reply": "2021-10-26T07:02:46.164341Z"
        },
        "trusted": true
      },
      "source": [
        "#block 4 : Min-max preprocessing of training and test data\n",
        "train_data_mM = train_data / 255 #min-max\n",
        "test_data_mM = test_data / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAis89AmbWox",
        "execution": {
          "iopub.status.busy": "2021-10-26T07:02:46.168549Z",
          "iopub.execute_input": "2021-10-26T07:02:46.168885Z",
          "iopub.status.idle": "2021-10-26T07:04:15.641769Z",
          "shell.execute_reply.started": "2021-10-26T07:02:46.168841Z",
          "shell.execute_reply": "2021-10-26T07:04:15.640579Z"
        },
        "trusted": true
      },
      "source": [
        "#block 5 : PCA preprocessing of training and test data\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(train_data_mM)\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "#plot the explained variance vs number of dimensions\n",
        "plt.figure(figsize = (6,4))\n",
        "plt.plot(cumsum, linewidth=3)\n",
        "plt.axis([0, 45, 0, 1])\n",
        "plt.xlabel(\"dimensions\")\n",
        "plt.ylabel(\"explained variance\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#choosing 25 dimensions: n_components = 0.80\n",
        "pca = PCA(n_components = 0.80)\n",
        "pca.fit(train_data_mM)\n",
        "\n",
        "#dimension\n",
        "train_data_pca = pca.transform(train_data_mM)\n",
        "test_data_pca = pca.transform(test_data_mM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5epIUwQCbaoc"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1E7f-o0bhxN",
        "execution": {
          "iopub.status.busy": "2021-10-26T07:04:15.644052Z",
          "iopub.execute_input": "2021-10-26T07:04:15.644843Z"
        },
        "trusted": true
      },
      "source": [
        "#Block 6\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Split the training data into training data and test data when training the model\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data_pca, train_label, stratify=train_label, random_state=42)\n",
        "\n",
        "print(\"Size of train and train label set: {}, {}.\".format(X_train.shape,y_train.shape))\n",
        "print(\"Size of test and test label set: {}, {}.\".format(X_test.shape,y_test.shape))\n",
        "\n",
        "# training the SVM model\n",
        "lin_svm=SVC(kernel=\"linear\",decision_function_shape=\"ovr\")\n",
        "poly_svm=SVC(kernel=\"poly\",degree=2,decision_function_shape=\"ovr\")\n",
        "\n",
        "#training linear model\n",
        "lin_svm.fit(X_train,y_train)\n",
        "y_pred_lin=lin_svm.predict(X_test)\n",
        "\n",
        "#training poly model\n",
        "poly_svm.fit(X_train,y_train)\n",
        "y_pred_poly=poly_svm.predict(X_test)\n",
        "\n",
        "print(\"Accuracy on test set using linear svm: {:.3f}\".format(accuracy_score(y_test,y_pred_lin)))\n",
        "print(\"Accuracy on test set quadratic svm: {:.3f}\".format(accuracy_score(y_test,y_pred_poly)))\n",
        "\n",
        "# training the KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "knn.fit(X_train,y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(\"Accuracy on test set: {:.2f}\".format(accuracy_score(y_test,y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBcSSQ7TmlL3",
        "trusted": true
      },
      "source": [
        "#Block 7\n",
        "### 10-fold to find the best parameter for SVM\n",
        "param_grid={'degree':[2,3,4]}\n",
        "print(\"Parameter grid:\\n{}\".format(param_grid))\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "### Using grid search to fit\n",
        "svm = SVC(kernel= 'poly')\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=10, \n",
        "                           return_train_score=True, n_jobs = -1)\n",
        "grid_search.fit(train_data_pca, train_label)\n",
        "\n",
        "### Typing the best parameters and cross-validation score\n",
        "print(\"Test set score: {:.2f}\".format(grid_search.score(test_data_pca,test_label)))\n",
        "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
        "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
        "\n",
        "### Printing the whole results\n",
        "resultSVM = grid_search.cv_results_\n",
        "result_pretty = pd.DataFrame(resultSVM)\n",
        "print(result_pretty.params)\n",
        "print(result_pretty.mean_test_score)\n",
        "\n",
        "### 10-fold to find the best parameter for KNN\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'n_neighbors' : [3, 5, 7], 'p' : [1, 2]}\n",
        "print(\"Parameter grid:\\n{}\".format(param_grid))\n",
        "\n",
        "### Using grid search to fit\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, return_train_score=True, n_jobs = -1)\n",
        "grid_search.fit(train_data_pca, train_label)\n",
        "\n",
        "### Typing the best parameters and cross-validation score\n",
        "print(\"Test set score: {:.2f}\".format(grid_search.score(test_data_pca,test_label)))\n",
        "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
        "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
        "\n",
        "### Printing the whole results\n",
        "resultKNN = grid_search.cv_results_\n",
        "result_pretty = pd.DataFrame(resultKNN)\n",
        "print(result_pretty.params)\n",
        "print(result_pretty.mean_test_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yGZ69czYYsaZ"
      },
      "source": [
        "#Block 8\n",
        "### Using hyper parameter to determine values\n",
        "\n",
        "poly_svm = SVC(kernel=\"poly\",degree=2)#polynomial kernel with degree 2\n",
        "poly_svm.fit(train_data_pca, train_label)\n",
        "label_pred_poly = poly_svm.predict(test_data_pca)\n",
        "\n",
        "### Using hyper parameter to determine accuracy for SVM\n",
        "print(\"Accuracy on test set: {:.3f}\".format(accuracy_score(test_label, label_pred_poly)))\n",
        "\n",
        "### Using hyper parameter to determine precisions including macro and micro averages\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(\"Precision of macro average on test set: {:.3f}\".format(precision_score(test_label, label_pred_poly, average='macro')))\n",
        "print(\"Precision of micro average on test set: {:.3f}\".format(precision_score(test_label, label_pred_poly, average='micro')))\n",
        "\n",
        "### Using hyper parameter to determine recall for SVM\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(\"Recall on test set: {:.3f}\".format(recall_score(test_label, label_pred_poly, average='micro')))\n",
        "\n",
        "\n",
        "### Using hyper parameter to determine accuracy for KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=7, p=2)\n",
        "knn.fit(train_data_pca, train_label)\n",
        "\n",
        "label_pred = knn.predict(test_data_pca)\n",
        "print(\"Accuracy on test set: {:.3f}\".format(accuracy_score(test_label, label_pred)))\n",
        "\n",
        "### Using hyper parameter to determine precision for KNN\n",
        "print(\"Precision of macro average on test set: {:.3f}\".format(precision_score(test_label, label_pred, average='macro')))\n",
        "print(\"Precision of micro average on test set: {:.3f}\".format(precision_score(test_label, label_pred, average='micro')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}